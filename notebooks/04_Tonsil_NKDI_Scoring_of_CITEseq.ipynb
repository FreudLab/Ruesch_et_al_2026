{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce77bde9-3341-478f-99e4-3103be7dc1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import muon as mu\n",
    "import mudata as md\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import loompy as lp\n",
    "import os\n",
    "import warnings\n",
    "import scipy\n",
    "import celltypist\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2ae39fb-09e4-4af3-9ede-6654403a5ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<muon._core.config.set_options at 0x147102309eb0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu.set_options(pull_on_update = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2a624fd-e34b-47f3-a127-171373cd68da",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_14_data_combined = mu.read_h5mu('D14_CITESeq_ALL.h5mu')\n",
    "day_28_data_combined = mu.read_h5mu('D28_CITESeq_ALL.h5mu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc54527-9271-40fe-a131-16797b3d2b9f",
   "metadata": {},
   "source": [
    "## Create NK specific mudata objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f969878-79fa-440e-b3a0-19eeece9b54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Subsetting successful! D14 NK cells: 573\n",
      "✅ Subsetting successful! D28 NK cells: 2729\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 1. Process Day 14 NK Subset\n",
    "# ==========================================\n",
    "\n",
    "# Remove the old neighbor graph from the parent object.\n",
    "# It causes the \"incorrect shape\" crash and we don't need it for the subset.\n",
    "for key in list(day_14_data_combined.obsp.keys()):\n",
    "    del day_14_data_combined.obsp[key]\n",
    "\n",
    "# Also clear the uns['neighbors'] if it exists, just to be clean\n",
    "if 'neighbors' in day_14_data_combined.uns:\n",
    "    del day_14_data_combined.uns['neighbors']\n",
    "\n",
    "# Define clusters to pull in all NK clusters\n",
    "clusters_to_keep = ['NK', 'pNK']\n",
    "\n",
    "#Name of the obs columns we are subsetting on\n",
    "obs_col = 'celltype' \n",
    "\n",
    "# NOW Subset\n",
    "D14_NK = day_14_data_combined[day_14_data_combined.obs[obs_col].isin(clusters_to_keep)].copy()\n",
    "\n",
    "print(f\"✅ Subsetting successful! D14 NK cells: {D14_NK.n_obs}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Now continue with re-analysis...\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# Recompute RNA\n",
    "sc.pp.pca(D14_NK.mod['rna'], svd_solver='arpack', random_state=123)\n",
    "sc.pp.neighbors(D14_NK.mod['rna'], n_neighbors=10, random_state=123)\n",
    "sc.tl.leiden(D14_NK.mod['rna'], resolution=0.5, random_state=123, key_added='leiden_reculstered')\n",
    "sc.tl.umap(D14_NK.mod['rna'], random_state=123)\n",
    "\n",
    "# Recompute Protein\n",
    "sc.pp.pca(D14_NK.mod['prot'], svd_solver='arpack', random_state=123)\n",
    "sc.pp.neighbors(D14_NK.mod['prot'], n_neighbors=10, random_state=123)\n",
    "sc.tl.leiden(D14_NK.mod['prot'], resolution=0.5, random_state=123, key_added='leiden_reculstered')\n",
    "sc.tl.umap(D14_NK.mod['prot'], random_state=123)\n",
    "\n",
    "# Recompute Global (WNN)\n",
    "mu.pp.neighbors(D14_NK, n_neighbors=10, random_state=123)\n",
    "mu.tl.leiden(D14_NK, resolution=0.5, random_state=123, key_added='leiden_reculstered')\n",
    "mu.tl.umap(D14_NK, random_state=123)\n",
    "\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 2. Process Day 28 NK Subset\n",
    "# ==========================================\n",
    "# Remove the old neighbor graph from the parent object.\n",
    "# It causes the \"incorrect shape\" crash and we don't need it for the subset.\n",
    "for key in list(day_28_data_combined.obsp.keys()):\n",
    "    del day_28_data_combined.obsp[key]\n",
    "\n",
    "# Also clear the uns['neighbors'] if it exists, just to be clean\n",
    "if 'neighbors' in day_28_data_combined.uns:\n",
    "    del day_28_data_combined.uns['neighbors']\n",
    "\n",
    "# Define clusters to pull in all NK clusters\n",
    "clusters_to_keep = ['NK', 'pNK']\n",
    "\n",
    "#Name of the obs columns we are subsetting on\n",
    "obs_col = 'celltype' \n",
    "\n",
    "# NOW Subset\n",
    "D28_NK = day_28_data_combined[day_28_data_combined.obs[obs_col].isin(clusters_to_keep)].copy()\n",
    "\n",
    "print(f\"✅ Subsetting successful! D28 NK cells: {D28_NK.n_obs}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Now continue with re-analysis...\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# Recompute RNA\n",
    "sc.pp.pca(D28_NK.mod['rna'], svd_solver='arpack', random_state=123)\n",
    "sc.pp.neighbors(D28_NK.mod['rna'], n_neighbors=10, random_state=123)\n",
    "sc.tl.leiden(D28_NK.mod['rna'], resolution=0.5, random_state=123, key_added='leiden_reculstered')\n",
    "sc.tl.umap(D28_NK.mod['rna'], random_state=123)\n",
    "\n",
    "# Recompute Protein\n",
    "sc.pp.pca(D28_NK.mod['prot'], svd_solver='arpack', random_state=123)\n",
    "sc.pp.neighbors(D28_NK.mod['prot'], n_neighbors=10, random_state=123)\n",
    "sc.tl.leiden(D28_NK.mod['prot'], resolution=0.5, random_state=123, key_added='leiden_reculstered')\n",
    "sc.tl.umap(D28_NK.mod['prot'], random_state=123)\n",
    "\n",
    "# Recompute Global (WNN)\n",
    "mu.pp.neighbors(D28_NK, n_neighbors=10, random_state=123)\n",
    "mu.tl.leiden(D28_NK, resolution=0.5, random_state=123, key_added='leiden_reculstered')\n",
    "mu.tl.umap(D28_NK, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dc02f0-6cbc-4b79-898c-b87abcb08c06",
   "metadata": {},
   "source": [
    "Generate a column that subsets the NK by CD16 (Stage 4 and Stage 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2924d32e-cc60-459e-a7f3-9233a10c6c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Day 14 data\n",
    "#Seperating by CD16+ and Negative\n",
    "# 1. Grab the expression values (handles sparse/dense/layers automatically)\n",
    "vals = sc.get.obs_df(D14_NK['prot'], keys=['CD16_TotalSeqC'])\n",
    "\n",
    "# 2. Create the new column using np.where\n",
    "# Syntax: np.where(condition, value_if_true, value_if_false)\n",
    "D14_NK['prot'].obs['CD16_status'] = np.where(vals['CD16_TotalSeqC'] >= 10, 'S5', 'S4')\n",
    "D14_NK['rna'].obs['CD16_status'] = D14_NK['prot'].obs['CD16_status']\n",
    "D14_NK['rna'].obs[\"CD16_cell_condition\"] = np.where(\n",
    "    D14_NK['rna'].obs[\"cell_condition\"].str.contains(\"pNK\", regex=True),\n",
    "    D14_NK['rna'].obs[\"cell_condition\"],  # use only cell_condition\n",
    "    D14_NK['rna'].obs[\"CD16_status\"].astype(str) + \"_\" + D14_NK['rna'].obs[\"cell_condition\"].astype(str)\n",
    ")\n",
    "\n",
    "#Day 28 Data\n",
    "#Seperating by CD16+ and Negative\n",
    "# 1. Grab the expression values (handles sparse/dense/layers automatically)\n",
    "vals = sc.get.obs_df(D28_NK['prot'], keys=['CD16_TotalSeqC'])\n",
    "\n",
    "# 2. Create the new column using np.where\n",
    "# Syntax: np.where(condition, value_if_true, value_if_false)\n",
    "D28_NK['prot'].obs['CD16_status'] = np.where(vals['CD16_TotalSeqC'] >= 8, 'S5', 'S4')\n",
    "D28_NK['rna'].obs['CD16_status'] = D28_NK['prot'].obs['CD16_status']\n",
    "D28_NK['rna'].obs[\"CD16_cell_condition\"] = np.where(\n",
    "    D28_NK['rna'].obs[\"cell_condition\"].str.contains(\"pNK\", regex=True),\n",
    "    D28_NK['rna'].obs[\"cell_condition\"],  # use only cell_condition\n",
    "    D28_NK['rna'].obs[\"CD16_status\"].astype(str) + \"_\" + D28_NK['rna'].obs[\"cell_condition\"].astype(str)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b523953-e4eb-41ec-a3eb-e45f0a6cdf16",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## NK speciic pyscenic run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06a2182b-32a5-490f-8c5a-d1cdcdab7c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "adatas = [D14_NK, D28_NK]\n",
    "names = [\"D14_NK\", \"D28_NK\"]\n",
    "#os.mkdir('pyscenic') #remove hash to make the directory that will save the loom files\n",
    "\n",
    "for ad, name in zip(adatas, names):\n",
    "    ad['rna'].X = ad['rna'].layers['counts'].copy()\n",
    "    \n",
    "    adata_row_attrs = {\n",
    "        'Gene': np.array(ad['rna'].var_names)\n",
    "        }\n",
    "    adata_col_attrs = {\n",
    "        'CellID': np.array(ad['rna'].obs_names),\n",
    "        'nGene': np.array(np.sum(ad['rna'].X.transpose() > 0, axis=0)).flatten(),\n",
    "        'nUMI': np.array(np.sum(ad['rna'].X.transpose(), axis=0)).flatten()\n",
    "        }\n",
    "    \n",
    "    lp.create(f'pyscenic/{name}.loom', ad['rna'].X.transpose(), adata_row_attrs, adata_col_attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fe95da3-f59e-40c5-8c9c-6cc3f6791a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing pyscenic/NK_run_pyscenic_job.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile pyscenic/NK_run_pyscenic_job.sh\n",
    "#!/bin/bash\n",
    "#SBATCH --account=PAS2527\n",
    "#SBATCH --time=2:00:00\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --ntasks-per-node=80\n",
    "#SBATCH --partition=nextgen\n",
    "#SBATCH --output=CITEseq_NK_pyscenic.slurm-%j.out\n",
    "#SBATCH --error=CITEseq_NK_pyscenic.slurm-%j.err\n",
    "\n",
    "# Exit on error\n",
    "set -e\n",
    "\n",
    "# Load modules and activate conda environment with pyscenic\n",
    "module load miniconda3/24.1.2-py310\n",
    "source activate pyscenic\n",
    "\n",
    "# ==============================================================================\n",
    "# CONFIGURATION\n",
    "# ==============================================================================\n",
    "# Define the source directory to make the script cleaner\n",
    "SRC_DIR=\"$HOME/Single_Cell_Files/03012023_CITESeq/scanpy_muon/pyscenic\"\n",
    "DB_DIR=\"$HOME/Single_Cell_Files/03012023_CITESeq/scanpy_muon/pyscenic/pySCENIC_files\"\n",
    "\n",
    "# Copy Static Database Files to $TMPDIR (Do this once)\n",
    "echo \"Copying reference databases to $TMPDIR...\"\n",
    "rsync -av $DB_DIR/allTFs_hg38.txt $TMPDIR/\n",
    "rsync -av $DB_DIR/motifs-v10nr_clust-nr.hgnc-m0.001-o0.0.tbl $TMPDIR/\n",
    "rsync -av $DB_DIR/hg38_10kbp_up_10kbp_down_full_tx_v10_clust.genes_vs_motifs.rankings.feather $TMPDIR/\n",
    "rsync -av $DB_DIR/hg38_500bp_up_100bp_down_full_tx_v10_clust.genes_vs_motifs.rankings.feather $TMPDIR/\n",
    "\n",
    "# Move to scratch\n",
    "cd $TMPDIR\n",
    "\n",
    "# ==============================================================================\n",
    "# FUNCTION: Run Pipeline for a specific Sample\n",
    "# ==============================================================================\n",
    "run_pyscenic() {\n",
    "    SAMPLE_ID=$1\n",
    "    echo \"----------------------------------------------------------------\"\n",
    "    echo \"STARTING PIPELINE FOR: $SAMPLE_ID\"\n",
    "    echo \"----------------------------------------------------------------\"\n",
    "\n",
    "    # 1. Copy specific loom file to TMP\n",
    "    echo \"Copying $SAMPLE_ID.loom...\"\n",
    "    rsync -av $SRC_DIR/$SAMPLE_ID.loom $TMPDIR/\n",
    "\n",
    "    # 2. GRN Step\n",
    "    echo \"Running GRN for $SAMPLE_ID...\"\n",
    "    pyscenic grn \\\n",
    "        -o ${SAMPLE_ID}_adj.csv \\\n",
    "        ${SAMPLE_ID}.loom allTFs_hg38.txt \\\n",
    "        --num_workers 80 \\\n",
    "        --seed 123\n",
    "\n",
    "    # 3. CTX Step\n",
    "    # Note: Outputting as .csv (standard), assumed previously .yml in your script\n",
    "    echo \"Running CTX for $SAMPLE_ID...\"\n",
    "    pyscenic ctx \\\n",
    "        -o ${SAMPLE_ID}_reg.csv \\\n",
    "        --expression_mtx_fname ${SAMPLE_ID}.loom \\\n",
    "        --annotations_fname motifs-v10nr_clust-nr.hgnc-m0.001-o0.0.tbl \\\n",
    "        ${SAMPLE_ID}_adj.csv \\\n",
    "        hg38_10kbp_up_10kbp_down_full_tx_v10_clust.genes_vs_motifs.rankings.feather \\\n",
    "        hg38_500bp_up_100bp_down_full_tx_v10_clust.genes_vs_motifs.rankings.feather \\\n",
    "        --num_workers 40 \\\n",
    "        --mode custom_multiprocessing \\\n",
    "        --mask_dropouts\n",
    "\n",
    "    # 4. AUCell Step\n",
    "    echo \"Running AUCell for $SAMPLE_ID...\"\n",
    "    pyscenic aucell \\\n",
    "        -o ${SAMPLE_ID}_pyscenic_results.loom \\\n",
    "        ${SAMPLE_ID}.loom ${SAMPLE_ID}_reg.csv \\\n",
    "        --num_workers 40 \\\n",
    "        --seed 123\n",
    "\n",
    "    # 5. Copy Results Back\n",
    "    echo \"Copying results for $SAMPLE_ID to a results folder\"\n",
    "    OUT_FOLDER=\"$SRC_DIR/${SAMPLE_ID}_results\"\n",
    "    mkdir -p $OUT_FOLDER\n",
    "    rsync -av ${SAMPLE_ID}_adj.csv $OUT_FOLDER\n",
    "    rsync -av ${SAMPLE_ID}_reg.csv $OUT_FOLDER\n",
    "    rsync -av ${SAMPLE_ID}_pyscenic_results.loom $OUT_FOLDER\n",
    "    \n",
    "    # Clean up loom from TMP to save space for next run\n",
    "    rm ${SAMPLE_ID}.loom\n",
    "    rm ${SAMPLE_ID}_adj.csv\n",
    "    rm ${SAMPLE_ID}_reg.csv\n",
    "    rm ${SAMPLE_ID}_pyscenic_results.loom\n",
    "    \n",
    "    echo \"Completed $SAMPLE_ID\"\n",
    "}\n",
    "\n",
    "# ==============================================================================\n",
    "# EXECUTION\n",
    "# ==============================================================================\n",
    "\n",
    "# Run for D28\n",
    "run_pyscenic \"D28_NK\"\n",
    "\n",
    "# Run for D14\n",
    "run_pyscenic \"D14_NK\"\n",
    "\n",
    "echo \"All samples processed successfully!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34282c0a-f2bc-4fb9-9b5a-9525c2adc2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading results for D14_NK from: pyscenic/D14_NK_results/D14_NK_pyscenic_results.loom\n",
      "✅ Success! Added 273 regulons to .obsm['NK_Pyscenic_AUC']\n",
      "----------------------------------------\n",
      "Loading results for D28_NK from: pyscenic/D28_NK_results/D28_NK_pyscenic_results.loom\n",
      "✅ Success! Added 219 regulons to .obsm['NK_Pyscenic_AUC']\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# CONFIGURATION\n",
    "# ==============================================================================\n",
    "# Update this to wherever your \"pyscenic\" folder lives relative to this notebook\n",
    "PYSCENIC_DIR = 'pyscenic' \n",
    "\n",
    "# ==============================================================================\n",
    "# FUNCTION: Import PySCENIC Results\n",
    "# ==============================================================================\n",
    "def import_pyscenic_results(mdata, sample_id):\n",
    "    \"\"\"\n",
    "    Loads AUCell matrix from Loom, cleans columns, aligns to MuData, and saves to .obsm\n",
    "    \"\"\"\n",
    "    # 1. Construct the path based on your Bash script's folder structure\n",
    "    #    Path: pyscenic/D28_results/D28_pyscenic_results.loom\n",
    "    loom_path = os.path.join(PYSCENIC_DIR, f\"{sample_id}_results\", f\"{sample_id}_pyscenic_results.loom\")\n",
    "    \n",
    "    if not os.path.exists(loom_path):\n",
    "        print(f\"❌ Error: File not found: {loom_path}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Loading results for {sample_id} from: {loom_path}\")\n",
    "    \n",
    "    # 2. Connect and load data\n",
    "    with lp.connect(loom_path, mode='r', validate=False) as lf:\n",
    "        auc_mtx = pd.DataFrame(lf.ca.RegulonsAUC, index=lf.ca.CellID)\n",
    "\n",
    "    # 3. Clean the column names (RegEx)\n",
    "    #    Turns \"Regulon(SOX2(+))\" -> \"SOX2\"\n",
    "    new_columns = [re.sub(r\"Regulon\\((\\w+)\\(.*\\)\\)\", r\"\\1\", c) for c in auc_mtx.columns]\n",
    "    auc_mtx.columns = new_columns\n",
    "\n",
    "    # 4. Re-index to match the specific MuData object\n",
    "    #    This ensures cells are in the exact same order as your mdata object\n",
    "    #    and fills missing cells with NaN (though there shouldn't be any if indices match)\n",
    "    auc_mtx = auc_mtx.reindex(mdata['rna'].obs_names)\n",
    "\n",
    "    # 5. Save to .obsm\n",
    "    mdata['rna'].obsm['NK_Pyscenic_AUC'] = auc_mtx\n",
    "\n",
    "    print(f\"✅ Success! Added {auc_mtx.shape[1]} regulons to .obsm['NK_Pyscenic_AUC']\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# ==============================================================================\n",
    "# EXECUTION\n",
    "# ==============================================================================\n",
    "\n",
    "# Run for Day 14\n",
    "import_pyscenic_results(D14_NK, \"D14_NK\")\n",
    "\n",
    "# Run for Day 28\n",
    "import_pyscenic_results(D28_NK, \"D28_NK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234619d2-bb88-44ab-a755-6ca264c8d4b5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Module Scoring based off of tonsil NKDIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a0f1bbf-06fb-47a4-8b88-fcc98ae9f055",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the tonsil and blood anndata objects generated from Li et al Cell Reports 2023 to capture the NKDI scoring at a single cell level\n",
    "tonsil_ad = sc.read_h5ad('/users/PAS1800/ruesch6/Single_Cell_Files/pySCENIC_Analyses/tonsil_ad.h5ad')\n",
    "blood_ad = sc.read_h5ad('/users/PAS1800/ruesch6/Single_Cell_Files/Anderson_Blood_NK_RNAseq/Scanpy/singlet_adata.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3f9e89c-4732-4135-a78d-fc25f1ab51df",
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=pd.errors.PerformanceWarning, message=\".*fragmented.*\")\n",
    "    sc.tl.rank_genes_groups(tonsil_ad, groupby='cell_type', method='wilcoxon', corr_method='benjamini-hochberg', layer='log_counts')\n",
    "    sc.tl.rank_genes_groups(tonsil_ad, groupby='leiden',group='28', method='wilcoxon', corr_method='benjamini-hochberg', layer='log_counts', key_added='pNK')\n",
    "    sc.tl.rank_genes_groups(blood_ad, groupby='cell_type', method='wilcoxon', corr_method='benjamini-hochberg', layer='log_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c723e961-11e5-4ed8-83ef-74261571b957",
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = ['Stage3', 'Stage4a', 'Stage4b', 'Stage5', 'pNK', 'CD56_bright', 'CD56_dim', 'Proliferating_NK']\n",
    "cell_dict = {}\n",
    "for cell in cells:\n",
    "    if cell == 'pNK':\n",
    "        x = sc.get.rank_genes_groups_df(tonsil_ad, group='28', log2fc_min=0, pval_cutoff=0.05, key=cell)\n",
    "        genes = x['names'].tolist()[0:50]\n",
    "        cell_dict[cell] = genes\n",
    "    elif cell in ['CD56_bright', 'CD56_dim', 'Proliferating_NK']:\n",
    "        x = sc.get.rank_genes_groups_df(blood_ad, group=cell, log2fc_min=0, pval_cutoff=0.05)\n",
    "        genes = x['names'].tolist()[0:50]\n",
    "        cell_dict[cell] = genes\n",
    "    else:\n",
    "        x = sc.get.rank_genes_groups_df(tonsil_ad, group=cell, log2fc_min=0, pval_cutoff=0.05)\n",
    "        genes = x['names'].tolist()[0:50]\n",
    "        cell_dict[cell] = genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66eecdeb-980f-49f1-9197-6c44e193b972",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell in cells:\n",
    "    sc.tl.score_genes(D14_NK['rna'], gene_list=cell_dict[cell], layer='log_counts', score_name=f'{cell}_score')\n",
    "    sc.tl.score_genes(D28_NK['rna'], gene_list=cell_dict[cell], layer='log_counts', score_name=f'{cell}_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde074ad-e813-4f3c-a56d-bf799c605cda",
   "metadata": {},
   "source": [
    "## Saving\n",
    "Save the NK specific mudata objects as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c4b30e9-adbc-49fe-90f3-4d1ca8728926",
   "metadata": {},
   "outputs": [],
   "source": [
    "D14_NK.write_h5mu('D14_CITESeq_NK.h5mu', compression = 'lzf')\n",
    "D28_NK.write_h5mu('D28_CITESeq_NK.h5mu', compression = 'lzf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcd1175-bbe1-44b5-954e-32f5e9c9483e",
   "metadata": {},
   "source": [
    "## Session Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cef40817-027f-44de-b676-df988f572d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<details>\n",
       "<summary>Click to view session information</summary>\n",
       "<pre>\n",
       "-----\n",
       "anndata             0.12.7\n",
       "celltypist          1.6.3\n",
       "loompy              3.0.8\n",
       "mudata              0.3.1\n",
       "muon                0.1.6\n",
       "numpy               2.3.5\n",
       "pandas              2.3.3\n",
       "scanpy              1.11.5\n",
       "scipy               1.17.0\n",
       "session_info        1.0.0\n",
       "-----\n",
       "</pre>\n",
       "<details>\n",
       "<summary>Click to view modules imported as dependencies</summary>\n",
       "<pre>\n",
       "Cython                      3.0.12\n",
       "PIL                         12.1.0\n",
       "anyio                       NA\n",
       "argcomplete                 NA\n",
       "arrow                       1.3.0\n",
       "asttokens                   NA\n",
       "attr                        24.2.0\n",
       "attrs                       24.2.0\n",
       "babel                       2.17.0\n",
       "brotli                      1.1.0\n",
       "certifi                     2026.01.04\n",
       "cffi                        1.17.1\n",
       "charset_normalizer          3.4.0\n",
       "cloudpickle                 3.1.0\n",
       "colorama                    0.4.6\n",
       "comm                        0.2.2\n",
       "cycler                      0.12.1\n",
       "cython                      3.0.12\n",
       "cython_runtime              NA\n",
       "cytoolz                     1.0.0\n",
       "dask                        2024.10.0\n",
       "dateutil                    2.9.0.post0\n",
       "debugpy                     1.8.7\n",
       "decorator                   5.1.1\n",
       "defusedxml                  0.7.1\n",
       "distutils                   3.12.7\n",
       "donfig                      0.8.1.post1\n",
       "executing                   2.1.0\n",
       "fastjsonschema              NA\n",
       "fqdn                        NA\n",
       "fsspec                      2024.10.0\n",
       "google_crc32c               NA\n",
       "h5py                        3.15.1\n",
       "idna                        3.10\n",
       "igraph                      0.11.6\n",
       "ipykernel                   6.29.5\n",
       "ipywidgets                  8.1.5\n",
       "isoduration                 NA\n",
       "jaraco                      NA\n",
       "jedi                        0.19.1\n",
       "jinja2                      3.1.4\n",
       "joblib                      1.5.3\n",
       "json5                       0.12.0\n",
       "jsonpointer                 3.0.0\n",
       "jsonschema                  4.23.0\n",
       "jsonschema_specifications   NA\n",
       "jupyter_events              0.12.0\n",
       "jupyter_server              2.15.0\n",
       "jupyterlab_server           2.27.3\n",
       "kiwisolver                  1.4.9\n",
       "legacy_api_wrap             NA\n",
       "leidenalg                   0.10.2\n",
       "llvmlite                    0.46.0\n",
       "louvain                     0.8.2\n",
       "lz4                         4.3.3\n",
       "markupsafe                  3.0.2\n",
       "matplotlib                  3.10.8\n",
       "more_itertools              10.5.0\n",
       "mpl_toolkits                NA\n",
       "msgpack                     1.1.0\n",
       "natsort                     8.4.0\n",
       "nbformat                    5.10.4\n",
       "numba                       0.63.1\n",
       "numcodecs                   0.16.5\n",
       "numexpr                     2.14.1\n",
       "numpy_groupies              0.11.2\n",
       "overrides                   NA\n",
       "packaging                   25.0\n",
       "parso                       0.8.4\n",
       "patsy                       1.0.2\n",
       "pickleshare                 0.7.5\n",
       "pkg_resources               NA\n",
       "platformdirs                4.3.6\n",
       "plotly                      6.0.0\n",
       "prometheus_client           NA\n",
       "prompt_toolkit              3.0.48\n",
       "psutil                      6.1.0\n",
       "pure_eval                   0.2.3\n",
       "pyarrow                     17.0.0\n",
       "pycparser                   2.22\n",
       "pydev_ipython               NA\n",
       "pydevconsole                NA\n",
       "pydevd                      3.1.0\n",
       "pydevd_file_utils           NA\n",
       "pydevd_plugins              NA\n",
       "pydevd_tracing              NA\n",
       "pygments                    2.18.0\n",
       "pynndescent                 0.6.0\n",
       "pyparsing                   3.3.1\n",
       "pythonjsonlogger            NA\n",
       "pytz                        2025.2\n",
       "referencing                 NA\n",
       "requests                    2.32.3\n",
       "rfc3339_validator           0.1.4\n",
       "rfc3986_validator           0.1.1\n",
       "rpds                        NA\n",
       "seaborn                     0.13.2\n",
       "send2trash                  NA\n",
       "setuptools                  75.1.0\n",
       "setuptools_scm              NA\n",
       "six                         1.17.0\n",
       "sklearn                     1.8.0\n",
       "sniffio                     1.3.1\n",
       "socks                       1.7.1\n",
       "stack_data                  0.6.2\n",
       "statsmodels                 0.14.6\n",
       "stdlib_list                 0.11.0\n",
       "tblib                       3.0.0\n",
       "testing                     NA\n",
       "texttable                   1.7.0\n",
       "threadpoolctl               3.6.0\n",
       "tlz                         1.0.0\n",
       "toolz                       1.0.0\n",
       "tornado                     6.4.1\n",
       "tqdm                        4.67.1\n",
       "traitlets                   5.14.3\n",
       "typing_extensions           NA\n",
       "umap                        0.5.11\n",
       "uri_template                NA\n",
       "urllib3                     2.2.3\n",
       "wcwidth                     0.2.13\n",
       "webcolors                   NA\n",
       "websocket                   1.8.0\n",
       "yaml                        6.0.3\n",
       "zarr                        3.1.5\n",
       "zmq                         26.2.0\n",
       "zstandard                   0.23.0\n",
       "</pre>\n",
       "</details> <!-- seems like this ends pre, so might as well be explicit -->\n",
       "<pre>\n",
       "-----\n",
       "IPython             8.29.0\n",
       "jupyter_client      8.6.3\n",
       "jupyter_core        5.7.2\n",
       "jupyterlab          4.3.6\n",
       "notebook            7.3.3\n",
       "-----\n",
       "Python 3.12.7 | packaged by conda-forge | (main, Oct  4 2024, 16:05:46) [GCC 13.3.0]\n",
       "Linux-5.14.0-427.102.1.el9_4.x86_64-x86_64-with-glibc2.34\n",
       "-----\n",
       "Session information updated at 2026-02-03 12:30\n",
       "</pre>\n",
       "</details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import session_info\n",
    "session_info.show(excludes=['distributed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e93efd1-2d01-4a90-acaf-9b66135fcde9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "single_cell",
   "language": "python",
   "name": "single_cell"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
